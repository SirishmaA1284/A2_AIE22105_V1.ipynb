{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvKyU1NAKPLD",
        "outputId": "fdf36aad-a570-4152-e8ee-9ca671bb5da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "     Gender  Height  Weight\n",
            "490  Female     164      59\n",
            "491  Female     146     147\n",
            "492  Female     198      50\n",
            "493  Female     170      53\n",
            "494    Male     152      98\n",
            "495  Female     150     153\n",
            "496  Female     184     121\n",
            "497  Female     141     136\n",
            "498    Male     150      95\n",
            "499    Male     173     131\n",
            "\n",
            "Label Encoded Data:\n",
            "     Gender  Height  Weight\n",
            "490       1     164      59\n",
            "491       1     146     147\n",
            "492       1     198      50\n",
            "493       1     170      53\n",
            "494       0     152      98\n",
            "495       1     150     153\n",
            "496       1     184     121\n",
            "497       1     141     136\n",
            "498       0     150      95\n",
            "499       0     173     131\n",
            "\n",
            "One-Hot Encoded Data:\n",
            "     Height  Weight  Gender_Male\n",
            "490     164      59            0\n",
            "491     146     147            0\n",
            "492     198      50            0\n",
            "493     170      53            0\n",
            "494     152      98            1\n",
            "495     150     153            0\n",
            "496     184     121            0\n",
            "497     141     136            0\n",
            "498     150      95            1\n",
            "499     173     131            1\n",
            "\n",
            "Example Euclidean Distance Calculation:\n",
            "Euclidean Distance between last two rows in the standardized test set: 3.1873422709402965\n",
            "\n",
            "Example Manhattan Distance Calculation:\n",
            "Manhattan Distance between last two rows in the standardized test set: 5.41381856921533\n",
            "\n",
            "Prediction using k-NN with k=3: 5\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Function to calculate Euclidean distance between two vectors\n",
        "def euclidean_distance(vector1, vector2):\n",
        "    squared_distances=[(a-b)**2 for a,b in zip(vector1, vector2)]\n",
        "    return math.sqrt(sum(squared_distances))\n",
        "\n",
        "# Function to calculate Manhattan distance between two vectors\n",
        "def manhattan_distance(vector1, vector2):\n",
        "    distance = sum(abs(x - y) for x, y in zip(vector1, vector2))\n",
        "    return distance\n",
        "\n",
        "# Function to convert categorical variables to numeric using label encoding\n",
        "def label_encoding(data, column):\n",
        "    labels = data[column].unique()\n",
        "    encoding_dict = {label: i for i, label in enumerate(labels)}\n",
        "    data[column] = data[column].map(encoding_dict)\n",
        "    return data\n",
        "\n",
        "# Function to convert categorical variables to numeric using One-Hot encoding\n",
        "def one_hot_encoding(data, column):\n",
        "    one_hot_encoded = pd.get_dummies(data[column], prefix=column, drop_first=True)\n",
        "    data = pd.concat([data, one_hot_encoded], axis=1)\n",
        "    data = data.drop(column, axis=1)\n",
        "    return data\n",
        "\n",
        "# Function to implement k-NN classifier\n",
        "def knn_classifier(X_train, y_train, X_test, k):\n",
        "    distances = []\n",
        "    for i in range(X_train.shape[0]):\n",
        "        distance = euclidean_distance(X_train[i], X_test)\n",
        "        distances.append((distance, y_train.iloc[i]))\n",
        "\n",
        "    distances.sort(key=lambda x: x[0])\n",
        "    neighbors = distances[:k]\n",
        "    neighbor_labels = [neighbor[1] for neighbor in neighbors]\n",
        "\n",
        "    # Use the most common label among the neighbors\n",
        "    prediction = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    return prediction\n",
        "\n",
        "# Main program\n",
        "if __name__ == \"__main__\":\n",
        "    # Load dataset\n",
        "    df = pd.read_csv('bmi.csv')\n",
        "\n",
        "    # Features (X) and Labels (y)\n",
        "    X = df[['Gender', 'Height', 'Weight']]\n",
        "    y = df['Index']\n",
        "\n",
        "    # Convert categorical variables to numeric using label encoding\n",
        "    X_label_encoded = label_encoding(X.copy(), 'Gender')\n",
        "\n",
        "    # Convert categorical variables to numeric using One-Hot encoding\n",
        "    X_one_hot_encoded = one_hot_encoding(X.copy(), 'Gender')\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_one_hot_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_std = scaler.fit_transform(X_train)\n",
        "    X_test_std = scaler.transform(X_test)\n",
        "\n",
        "    # Display original and encoded data\n",
        "    print(\"Original Data:\")\n",
        "    print(X.tail(10))\n",
        "    print(\"\\nLabel Encoded Data:\")\n",
        "    print(X_label_encoded.tail(10))\n",
        "    print(\"\\nOne-Hot Encoded Data:\")\n",
        "    print(X_one_hot_encoded.tail(10))\n",
        "\n",
        "    # Calculate Euclidean distance for the last two rows in the standardized test set\n",
        "    euclidean_dist_example = euclidean_distance(X_test_std[-2], X_test_std[-1])\n",
        "    print(\"\\nExample Euclidean Distance Calculation:\")\n",
        "    print(f\"Euclidean Distance between last two rows in the standardized test set: {euclidean_dist_example}\")\n",
        "\n",
        "    # Calculate Manhattan distance for the last two rows in the standardized test set\n",
        "    manhattan_dist_example = manhattan_distance(X_test_std[-2], X_test_std[-1])\n",
        "    print(\"\\nExample Manhattan Distance Calculation:\")\n",
        "    print(f\"Manhattan Distance between last two rows in the standardized test set: {manhattan_dist_example}\")\n",
        "\n",
        "    #Use k-NN classifier with k=3\n",
        "    k_value = 3\n",
        "    prediction = knn_classifier(X_train_std, y_train, X_test_std[-1], k_value)\n",
        "\n",
        "    # Print the prediction\n",
        "    print(f\"\\nPrediction using k-NN with k={k_value}: {prediction}\")\n",
        "\n"
      ]
    }
  ]
}